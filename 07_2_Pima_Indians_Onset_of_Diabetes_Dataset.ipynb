{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07.2 Pima Indians Onset of Diabetes Dataset.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNaZgbjohqOPjn+As94NXWU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelounb/Deep_Learning_with_python_JasonBrownlee/blob/master/07_2_Pima_Indians_Onset_of_Diabetes_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvKOhxrOhpmC",
        "colab_type": "text"
      },
      "source": [
        "# 7.2 Pima Indians Onset of Diabetes Dataset\n",
        " patient medical record data for Pima Indians and whether they had an onset of diabetes within ﬁve years. It is a binary classiﬁcation problem (onset of diabetes as 1 or not as 0). The input variables that describe each patient are numerical and have varying scales. Below lists the eight attributes for the dataset:\n",
        "1. Number of times pregnant.\n",
        "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test.\n",
        "3. Diastolic blood pressure (mm Hg).\n",
        "4. Triceps skin fold thickness (mm).\n",
        "5. 2-Hour serum insulin (mu U/ml).\n",
        "6. Body mass index.\n",
        "7. Diabetes pedigree function.\n",
        "8. Age (years).\n",
        "9. Class, onset of diabetes within ﬁve years.\n",
        "\n",
        "Given that all attributes are numerical makes it easy to use directly with neural networks that expect numerical inputs and output values, and ideal for our ﬁrst neural network in Keras. This dataset will also be used for a number of additional lessons coming up in this book, so keep it handy. below is a sample of the dataset showing the ﬁrst 5 rows of the 768 instances:\n",
        "\n",
        "6,148,72,35,0,33.6,0.627,50,1 \n",
        "\n",
        "1,85,66,29,0,26.6,0.351,31,0 \n",
        "\n",
        "8,183,64,0,0,23.3,0.672,32,1 \n",
        "\n",
        "1,89,66,23,94,28.1,0.167,21,0 \n",
        "\n",
        "0,137,40,35,168,43.1,2.288,33,1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAX8Zec9kc-K",
        "colab_type": "text"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CPE29t-Bfaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52e667a4-83e9-4508-b73e-be34bae08e1e"
      },
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "import numpy as np\n",
        "# fix random seed for reproducibility \n",
        "seed = 7 \n",
        "np.random.seed(seed)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NphmfwqhkpTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load pima indians dataset \n",
        "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\") \n",
        "# split into input (X) and output (Y) variables \n",
        "X = dataset[:,0:8] \n",
        "Y = dataset[:,8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H39mtChk8Dv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "09516724-79b3-45df-9783-b217f8d403de"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc6Nxpalk_S7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e774924c-19ce-44dd-f4bb-b742a5209728"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S3XtyealLv5",
        "colab_type": "text"
      },
      "source": [
        "# Deﬁning the Model\n",
        "In this example we will use a fully-connected network structure with three layers.\n",
        "\n",
        "Fully connected layers are deﬁned using the Dense class. We can specify the number of neurons in the layer as the ﬁrst argument, the initialization method as the second argument as init and specify the activation function using the activation argument. In this case we initialize the network weights to a small random number generated from a uniform distribution (uniform), in this case between 0 and 0.05 because that is the default uniform weight initialization in Keras. Another traditional alternative would be normal for small random numbers generated from a Gaussian distribution.\n",
        "\n",
        "We will use the rectiﬁer (relu) activation function on the ﬁrst two layers and thesigmoid activation function in the output layer. It used to be the case that sigmoid and tanh activation functions were preferred for all layers. These days, better performance is seen using the rectiﬁer activation function. We use a sigmoid activation function on the output layer to ensure our network output is between 0 and 1 and easy to map to either a probability of class 1 or snap to a hard classiﬁcation of either class with a default threshold of 0.5. We can piece it all together by adding each layer. The ﬁrst hidden layer has 12 neurons and expects 8 input variables. The second hidden layer has 8 neurons and ﬁnally the output layer has 1 neuron to predict the class (onset of diabetes or not)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spamllKxlGHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model \n",
        "model = Sequential() \n",
        "model.add(Dense(12, input_dim=8, kernel_initializer= 'uniform' , activation= 'relu' )) \n",
        "model.add(Dense(8, kernel_initializer= 'uniform' , activation= 'relu' )) \n",
        "model.add(Dense(1, kernel_initializer= 'uniform' , activation= 'sigmoid' ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6cpa2dTm-N3",
        "colab_type": "text"
      },
      "source": [
        "# Compiling the Model\n",
        "Now that the model is deﬁned, we can compile it. Compiling the model uses the ecient numerical libraries under the covers (the so-called backend) such as Theano or TensorFlow. The backend automatically chooses the best way to represent the network for training and making predictions to run on your hardware. When compiling, we must specify some additional properties required when training the network. Remember training a network means ﬁnding the best set of weights to make predictions for this problem.\n",
        "\n",
        "We must specify the loss function to use to evaluate a set of weights, the optimizer used to search through di↵erent weights for the network and any optional metrics we would like to collect and report during training. In this case we will use logarithmic loss, which for a binary classiﬁcation problem is deﬁned in Keras as binary crossentropy. We will also use the ecient gradient descent algorithm adam for no other reason that it is an ecient default. Learn more about the Adam optimization algorithm in the paper Adam: A Method for Stochastic Optimization (http://arxiv.org/abs/1412.6980). Finally, because it is a classiﬁcation problem, we will collect and report the classiﬁcation accuracy as the metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll6gDRvHl1Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model \n",
        "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dJhsHlOoA0I",
        "colab_type": "text"
      },
      "source": [
        "# Fiting the Model\n",
        "We have deﬁned our model and compiled it ready for ecient computation. Now it is time to execute the model on some data. We can train or ﬁt our model on our loaded data by calling the fit( ) function on the model. \n",
        "\n",
        "The training process will run for a ﬁxed number of iterations through the dataset called epochs, that we must specify using the nb epoch argument. We can also set the number of instances that are evaluated before a weight update in the network is performed called the batch size and set using the batch size argument. For this problem we will run for a small number of epochs (150) and use a relatively small batch size of 10. Again, these can be chosen experimentally by trial and error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR4pJkefnZ-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "85bf3f84-f12c-458f-8502-7399f3c0c474"
      },
      "source": [
        "#Model fit\n",
        "epochs_hist = model.fit(X, Y, epochs=300, batch_size=15)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "768/768 [==============================] - 0s 237us/step - loss: 0.6782 - accuracy: 0.6510\n",
            "Epoch 2/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.6625 - accuracy: 0.6510\n",
            "Epoch 3/300\n",
            "768/768 [==============================] - 0s 90us/step - loss: 0.6565 - accuracy: 0.6510\n",
            "Epoch 4/300\n",
            "768/768 [==============================] - 0s 89us/step - loss: 0.6503 - accuracy: 0.6510\n",
            "Epoch 5/300\n",
            "768/768 [==============================] - 0s 92us/step - loss: 0.6402 - accuracy: 0.6510\n",
            "Epoch 6/300\n",
            "768/768 [==============================] - 0s 88us/step - loss: 0.6301 - accuracy: 0.6510\n",
            "Epoch 7/300\n",
            "768/768 [==============================] - 0s 99us/step - loss: 0.6244 - accuracy: 0.6510\n",
            "Epoch 8/300\n",
            "768/768 [==============================] - 0s 87us/step - loss: 0.6158 - accuracy: 0.6510\n",
            "Epoch 9/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.6109 - accuracy: 0.6510\n",
            "Epoch 10/300\n",
            "768/768 [==============================] - 0s 90us/step - loss: 0.6174 - accuracy: 0.6510\n",
            "Epoch 11/300\n",
            "768/768 [==============================] - 0s 90us/step - loss: 0.6099 - accuracy: 0.6510\n",
            "Epoch 12/300\n",
            "768/768 [==============================] - 0s 87us/step - loss: 0.6028 - accuracy: 0.6510\n",
            "Epoch 13/300\n",
            "768/768 [==============================] - 0s 104us/step - loss: 0.6040 - accuracy: 0.6510\n",
            "Epoch 14/300\n",
            "768/768 [==============================] - 0s 92us/step - loss: 0.5992 - accuracy: 0.6510\n",
            "Epoch 15/300\n",
            "768/768 [==============================] - 0s 93us/step - loss: 0.5992 - accuracy: 0.6510\n",
            "Epoch 16/300\n",
            "768/768 [==============================] - 0s 92us/step - loss: 0.5998 - accuracy: 0.6510\n",
            "Epoch 17/300\n",
            "768/768 [==============================] - 0s 91us/step - loss: 0.5997 - accuracy: 0.6510\n",
            "Epoch 18/300\n",
            "768/768 [==============================] - 0s 100us/step - loss: 0.5994 - accuracy: 0.6510\n",
            "Epoch 19/300\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.5998 - accuracy: 0.6510\n",
            "Epoch 20/300\n",
            "768/768 [==============================] - 0s 93us/step - loss: 0.5958 - accuracy: 0.6510\n",
            "Epoch 21/300\n",
            "768/768 [==============================] - 0s 89us/step - loss: 0.5966 - accuracy: 0.6510\n",
            "Epoch 22/300\n",
            "768/768 [==============================] - 0s 94us/step - loss: 0.5956 - accuracy: 0.6510\n",
            "Epoch 23/300\n",
            "768/768 [==============================] - 0s 89us/step - loss: 0.5919 - accuracy: 0.6510\n",
            "Epoch 24/300\n",
            "768/768 [==============================] - 0s 94us/step - loss: 0.6057 - accuracy: 0.6510\n",
            "Epoch 25/300\n",
            "768/768 [==============================] - 0s 89us/step - loss: 0.5938 - accuracy: 0.6510\n",
            "Epoch 26/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.5962 - accuracy: 0.6510\n",
            "Epoch 27/300\n",
            "768/768 [==============================] - 0s 89us/step - loss: 0.5947 - accuracy: 0.6510\n",
            "Epoch 28/300\n",
            "768/768 [==============================] - 0s 87us/step - loss: 0.5878 - accuracy: 0.6510\n",
            "Epoch 29/300\n",
            "768/768 [==============================] - 0s 91us/step - loss: 0.5944 - accuracy: 0.6510\n",
            "Epoch 30/300\n",
            "768/768 [==============================] - 0s 96us/step - loss: 0.5902 - accuracy: 0.6510\n",
            "Epoch 31/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.5894 - accuracy: 0.6510\n",
            "Epoch 32/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.5882 - accuracy: 0.6510\n",
            "Epoch 33/300\n",
            "768/768 [==============================] - 0s 87us/step - loss: 0.5846 - accuracy: 0.6510\n",
            "Epoch 34/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.5893 - accuracy: 0.6510\n",
            "Epoch 35/300\n",
            "768/768 [==============================] - 0s 96us/step - loss: 0.5904 - accuracy: 0.6510\n",
            "Epoch 36/300\n",
            "768/768 [==============================] - 0s 94us/step - loss: 0.5847 - accuracy: 0.6510\n",
            "Epoch 37/300\n",
            "768/768 [==============================] - 0s 88us/step - loss: 0.5810 - accuracy: 0.6510\n",
            "Epoch 38/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.5930 - accuracy: 0.6510\n",
            "Epoch 39/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.5835 - accuracy: 0.6510\n",
            "Epoch 40/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.5884 - accuracy: 0.6510\n",
            "Epoch 41/300\n",
            "768/768 [==============================] - 0s 89us/step - loss: 0.5799 - accuracy: 0.7122\n",
            "Epoch 42/300\n",
            "768/768 [==============================] - 0s 87us/step - loss: 0.5808 - accuracy: 0.7070\n",
            "Epoch 43/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.5797 - accuracy: 0.7161\n",
            "Epoch 44/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.5874 - accuracy: 0.6992\n",
            "Epoch 45/300\n",
            "768/768 [==============================] - 0s 89us/step - loss: 0.5799 - accuracy: 0.7109\n",
            "Epoch 46/300\n",
            "768/768 [==============================] - 0s 87us/step - loss: 0.5775 - accuracy: 0.7083\n",
            "Epoch 47/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.5783 - accuracy: 0.7109\n",
            "Epoch 48/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.5768 - accuracy: 0.6914\n",
            "Epoch 49/300\n",
            "768/768 [==============================] - 0s 90us/step - loss: 0.5775 - accuracy: 0.7083\n",
            "Epoch 50/300\n",
            "768/768 [==============================] - 0s 90us/step - loss: 0.5739 - accuracy: 0.7135\n",
            "Epoch 51/300\n",
            "768/768 [==============================] - 0s 87us/step - loss: 0.5772 - accuracy: 0.7122\n",
            "Epoch 52/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.5744 - accuracy: 0.7174\n",
            "Epoch 53/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.5811 - accuracy: 0.6979\n",
            "Epoch 54/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.5737 - accuracy: 0.7135\n",
            "Epoch 55/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.5755 - accuracy: 0.7188\n",
            "Epoch 56/300\n",
            "768/768 [==============================] - 0s 91us/step - loss: 0.5773 - accuracy: 0.7135\n",
            "Epoch 57/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.5742 - accuracy: 0.7070\n",
            "Epoch 58/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.5779 - accuracy: 0.7031\n",
            "Epoch 59/300\n",
            "768/768 [==============================] - 0s 87us/step - loss: 0.5714 - accuracy: 0.7122\n",
            "Epoch 60/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.5745 - accuracy: 0.7057\n",
            "Epoch 61/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.5702 - accuracy: 0.7135\n",
            "Epoch 62/300\n",
            "768/768 [==============================] - 0s 99us/step - loss: 0.5726 - accuracy: 0.7174\n",
            "Epoch 63/300\n",
            "768/768 [==============================] - 0s 88us/step - loss: 0.5761 - accuracy: 0.7070\n",
            "Epoch 64/300\n",
            "768/768 [==============================] - 0s 90us/step - loss: 0.5734 - accuracy: 0.7018\n",
            "Epoch 65/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.5688 - accuracy: 0.7201\n",
            "Epoch 66/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.5679 - accuracy: 0.7161\n",
            "Epoch 67/300\n",
            "768/768 [==============================] - 0s 87us/step - loss: 0.5662 - accuracy: 0.7227\n",
            "Epoch 68/300\n",
            "768/768 [==============================] - 0s 92us/step - loss: 0.5746 - accuracy: 0.7096\n",
            "Epoch 69/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.5667 - accuracy: 0.7227\n",
            "Epoch 70/300\n",
            "768/768 [==============================] - 0s 83us/step - loss: 0.5774 - accuracy: 0.7109\n",
            "Epoch 71/300\n",
            "768/768 [==============================] - 0s 88us/step - loss: 0.5650 - accuracy: 0.7148\n",
            "Epoch 72/300\n",
            "768/768 [==============================] - 0s 87us/step - loss: 0.5647 - accuracy: 0.7201\n",
            "Epoch 73/300\n",
            "768/768 [==============================] - 0s 92us/step - loss: 0.5609 - accuracy: 0.7188\n",
            "Epoch 74/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.5584 - accuracy: 0.7070\n",
            "Epoch 75/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.5533 - accuracy: 0.7188\n",
            "Epoch 76/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.5533 - accuracy: 0.7227\n",
            "Epoch 77/300\n",
            "768/768 [==============================] - 0s 93us/step - loss: 0.5535 - accuracy: 0.7188\n",
            "Epoch 78/300\n",
            "768/768 [==============================] - 0s 90us/step - loss: 0.5501 - accuracy: 0.7174\n",
            "Epoch 79/300\n",
            "768/768 [==============================] - 0s 98us/step - loss: 0.5572 - accuracy: 0.7188\n",
            "Epoch 80/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.5522 - accuracy: 0.7188\n",
            "Epoch 81/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.5521 - accuracy: 0.7096\n",
            "Epoch 82/300\n",
            "768/768 [==============================] - 0s 74us/step - loss: 0.5548 - accuracy: 0.7148\n",
            "Epoch 83/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.5453 - accuracy: 0.7227\n",
            "Epoch 84/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.5452 - accuracy: 0.7161\n",
            "Epoch 85/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.5468 - accuracy: 0.7214\n",
            "Epoch 86/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.5477 - accuracy: 0.7174\n",
            "Epoch 87/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.5426 - accuracy: 0.7174\n",
            "Epoch 88/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.5403 - accuracy: 0.7266\n",
            "Epoch 89/300\n",
            "768/768 [==============================] - 0s 87us/step - loss: 0.5467 - accuracy: 0.7214\n",
            "Epoch 90/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.5405 - accuracy: 0.7201\n",
            "Epoch 91/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.5378 - accuracy: 0.7331\n",
            "Epoch 92/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.5364 - accuracy: 0.7266\n",
            "Epoch 93/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.5351 - accuracy: 0.7201\n",
            "Epoch 94/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.5352 - accuracy: 0.7240\n",
            "Epoch 95/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.5350 - accuracy: 0.7148\n",
            "Epoch 96/300\n",
            "768/768 [==============================] - 0s 76us/step - loss: 0.5347 - accuracy: 0.7292\n",
            "Epoch 97/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.5330 - accuracy: 0.7188\n",
            "Epoch 98/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.5332 - accuracy: 0.7292\n",
            "Epoch 99/300\n",
            "768/768 [==============================] - 0s 83us/step - loss: 0.5236 - accuracy: 0.7266\n",
            "Epoch 100/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.5381 - accuracy: 0.7279\n",
            "Epoch 101/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.5300 - accuracy: 0.7266\n",
            "Epoch 102/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.5250 - accuracy: 0.7227\n",
            "Epoch 103/300\n",
            "768/768 [==============================] - 0s 91us/step - loss: 0.5338 - accuracy: 0.7279\n",
            "Epoch 104/300\n",
            "768/768 [==============================] - 0s 90us/step - loss: 0.5340 - accuracy: 0.7357\n",
            "Epoch 105/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.5355 - accuracy: 0.7305\n",
            "Epoch 106/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.5251 - accuracy: 0.7318\n",
            "Epoch 107/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.5335 - accuracy: 0.7318\n",
            "Epoch 108/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.5236 - accuracy: 0.7344\n",
            "Epoch 109/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.5206 - accuracy: 0.7253\n",
            "Epoch 110/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.5197 - accuracy: 0.7318\n",
            "Epoch 111/300\n",
            "768/768 [==============================] - 0s 91us/step - loss: 0.5184 - accuracy: 0.7331\n",
            "Epoch 112/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.5220 - accuracy: 0.7305\n",
            "Epoch 113/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.5195 - accuracy: 0.7435\n",
            "Epoch 114/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.5147 - accuracy: 0.7357\n",
            "Epoch 115/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.5151 - accuracy: 0.7461\n",
            "Epoch 116/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.5159 - accuracy: 0.7474\n",
            "Epoch 117/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.5066 - accuracy: 0.7500\n",
            "Epoch 118/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.5211 - accuracy: 0.7396\n",
            "Epoch 119/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.5072 - accuracy: 0.7513\n",
            "Epoch 120/300\n",
            "768/768 [==============================] - 0s 83us/step - loss: 0.5066 - accuracy: 0.7461\n",
            "Epoch 121/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.5283 - accuracy: 0.7539\n",
            "Epoch 122/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.5168 - accuracy: 0.7513\n",
            "Epoch 123/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.5013 - accuracy: 0.7565\n",
            "Epoch 124/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.5031 - accuracy: 0.7539\n",
            "Epoch 125/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.4947 - accuracy: 0.7617\n",
            "Epoch 126/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.5002 - accuracy: 0.7552\n",
            "Epoch 127/300\n",
            "768/768 [==============================] - 0s 97us/step - loss: 0.5009 - accuracy: 0.7630\n",
            "Epoch 128/300\n",
            "768/768 [==============================] - 0s 83us/step - loss: 0.4918 - accuracy: 0.7630\n",
            "Epoch 129/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4952 - accuracy: 0.7630\n",
            "Epoch 130/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4914 - accuracy: 0.7786\n",
            "Epoch 131/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4939 - accuracy: 0.7682\n",
            "Epoch 132/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.4901 - accuracy: 0.7682\n",
            "Epoch 133/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.4931 - accuracy: 0.7669\n",
            "Epoch 134/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.4920 - accuracy: 0.7526\n",
            "Epoch 135/300\n",
            "768/768 [==============================] - 0s 76us/step - loss: 0.4894 - accuracy: 0.7591\n",
            "Epoch 136/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4850 - accuracy: 0.7526\n",
            "Epoch 137/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.5112 - accuracy: 0.7591\n",
            "Epoch 138/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4918 - accuracy: 0.7734\n",
            "Epoch 139/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4782 - accuracy: 0.7812\n",
            "Epoch 140/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4875 - accuracy: 0.7799\n",
            "Epoch 141/300\n",
            "768/768 [==============================] - 0s 83us/step - loss: 0.4801 - accuracy: 0.7721\n",
            "Epoch 142/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.4829 - accuracy: 0.7786\n",
            "Epoch 143/300\n",
            "768/768 [==============================] - 0s 83us/step - loss: 0.4935 - accuracy: 0.7591\n",
            "Epoch 144/300\n",
            "768/768 [==============================] - 0s 88us/step - loss: 0.4839 - accuracy: 0.7604\n",
            "Epoch 145/300\n",
            "768/768 [==============================] - 0s 83us/step - loss: 0.4856 - accuracy: 0.7747\n",
            "Epoch 146/300\n",
            "768/768 [==============================] - 0s 83us/step - loss: 0.4865 - accuracy: 0.7682\n",
            "Epoch 147/300\n",
            "768/768 [==============================] - 0s 91us/step - loss: 0.4771 - accuracy: 0.7799\n",
            "Epoch 148/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.4831 - accuracy: 0.7721\n",
            "Epoch 149/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4734 - accuracy: 0.7786\n",
            "Epoch 150/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4748 - accuracy: 0.7708\n",
            "Epoch 151/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4770 - accuracy: 0.7865\n",
            "Epoch 152/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4734 - accuracy: 0.7721\n",
            "Epoch 153/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4849 - accuracy: 0.7812\n",
            "Epoch 154/300\n",
            "768/768 [==============================] - 0s 97us/step - loss: 0.4734 - accuracy: 0.7799\n",
            "Epoch 155/300\n",
            "768/768 [==============================] - 0s 83us/step - loss: 0.4805 - accuracy: 0.7656\n",
            "Epoch 156/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4749 - accuracy: 0.7826\n",
            "Epoch 157/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4746 - accuracy: 0.7669\n",
            "Epoch 158/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.4722 - accuracy: 0.7747\n",
            "Epoch 159/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4723 - accuracy: 0.7747\n",
            "Epoch 160/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4690 - accuracy: 0.7917\n",
            "Epoch 161/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4683 - accuracy: 0.7799\n",
            "Epoch 162/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4681 - accuracy: 0.7747\n",
            "Epoch 163/300\n",
            "768/768 [==============================] - 0s 76us/step - loss: 0.4701 - accuracy: 0.7708\n",
            "Epoch 164/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4699 - accuracy: 0.7852\n",
            "Epoch 165/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4751 - accuracy: 0.7760\n",
            "Epoch 166/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4650 - accuracy: 0.7878\n",
            "Epoch 167/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4638 - accuracy: 0.7839\n",
            "Epoch 168/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.4688 - accuracy: 0.7708\n",
            "Epoch 169/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.4665 - accuracy: 0.7760\n",
            "Epoch 170/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4635 - accuracy: 0.7878\n",
            "Epoch 171/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4720 - accuracy: 0.7604\n",
            "Epoch 172/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4624 - accuracy: 0.7812\n",
            "Epoch 173/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4631 - accuracy: 0.7826\n",
            "Epoch 174/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.4766 - accuracy: 0.7786\n",
            "Epoch 175/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4634 - accuracy: 0.7786\n",
            "Epoch 176/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4623 - accuracy: 0.7865\n",
            "Epoch 177/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4761 - accuracy: 0.7760\n",
            "Epoch 178/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4614 - accuracy: 0.7969\n",
            "Epoch 179/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4619 - accuracy: 0.7904\n",
            "Epoch 180/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4606 - accuracy: 0.7943\n",
            "Epoch 181/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4614 - accuracy: 0.7891\n",
            "Epoch 182/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4721 - accuracy: 0.7799\n",
            "Epoch 183/300\n",
            "768/768 [==============================] - 0s 92us/step - loss: 0.4621 - accuracy: 0.7839\n",
            "Epoch 184/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4692 - accuracy: 0.7865\n",
            "Epoch 185/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4646 - accuracy: 0.7852\n",
            "Epoch 186/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4551 - accuracy: 0.7904\n",
            "Epoch 187/300\n",
            "768/768 [==============================] - 0s 75us/step - loss: 0.4667 - accuracy: 0.7878\n",
            "Epoch 188/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4669 - accuracy: 0.7760\n",
            "Epoch 189/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4583 - accuracy: 0.7747\n",
            "Epoch 190/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4569 - accuracy: 0.7904\n",
            "Epoch 191/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4520 - accuracy: 0.7956\n",
            "Epoch 192/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4655 - accuracy: 0.7773\n",
            "Epoch 193/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4517 - accuracy: 0.7930\n",
            "Epoch 194/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4544 - accuracy: 0.8008\n",
            "Epoch 195/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4662 - accuracy: 0.7734\n",
            "Epoch 196/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4505 - accuracy: 0.7878\n",
            "Epoch 197/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4492 - accuracy: 0.7917\n",
            "Epoch 198/300\n",
            "768/768 [==============================] - 0s 88us/step - loss: 0.4706 - accuracy: 0.7852\n",
            "Epoch 199/300\n",
            "768/768 [==============================] - 0s 83us/step - loss: 0.4607 - accuracy: 0.7865\n",
            "Epoch 200/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4881 - accuracy: 0.7591\n",
            "Epoch 201/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4534 - accuracy: 0.7747\n",
            "Epoch 202/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4602 - accuracy: 0.7839\n",
            "Epoch 203/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4614 - accuracy: 0.7904\n",
            "Epoch 204/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.4615 - accuracy: 0.7826\n",
            "Epoch 205/300\n",
            "768/768 [==============================] - 0s 76us/step - loss: 0.4478 - accuracy: 0.8034\n",
            "Epoch 206/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.4479 - accuracy: 0.8008\n",
            "Epoch 207/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4584 - accuracy: 0.7904\n",
            "Epoch 208/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4519 - accuracy: 0.7943\n",
            "Epoch 209/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4552 - accuracy: 0.7812\n",
            "Epoch 210/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4494 - accuracy: 0.8008\n",
            "Epoch 211/300\n",
            "768/768 [==============================] - 0s 90us/step - loss: 0.4438 - accuracy: 0.8112\n",
            "Epoch 212/300\n",
            "768/768 [==============================] - 0s 94us/step - loss: 0.4450 - accuracy: 0.7917\n",
            "Epoch 213/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4451 - accuracy: 0.7956\n",
            "Epoch 214/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4558 - accuracy: 0.7826\n",
            "Epoch 215/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4507 - accuracy: 0.8008\n",
            "Epoch 216/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4558 - accuracy: 0.7930\n",
            "Epoch 217/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4478 - accuracy: 0.7956\n",
            "Epoch 218/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4554 - accuracy: 0.7943\n",
            "Epoch 219/300\n",
            "768/768 [==============================] - 0s 76us/step - loss: 0.4562 - accuracy: 0.7943\n",
            "Epoch 220/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4559 - accuracy: 0.7826\n",
            "Epoch 221/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4513 - accuracy: 0.8021\n",
            "Epoch 222/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.4568 - accuracy: 0.7969\n",
            "Epoch 223/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4473 - accuracy: 0.7878\n",
            "Epoch 224/300\n",
            "768/768 [==============================] - 0s 76us/step - loss: 0.4454 - accuracy: 0.7982\n",
            "Epoch 225/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4544 - accuracy: 0.7839\n",
            "Epoch 226/300\n",
            "768/768 [==============================] - 0s 83us/step - loss: 0.4426 - accuracy: 0.7891\n",
            "Epoch 227/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4442 - accuracy: 0.7943\n",
            "Epoch 228/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4423 - accuracy: 0.8047\n",
            "Epoch 229/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4492 - accuracy: 0.7982\n",
            "Epoch 230/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4391 - accuracy: 0.7969\n",
            "Epoch 231/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4454 - accuracy: 0.8034\n",
            "Epoch 232/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4527 - accuracy: 0.7878\n",
            "Epoch 233/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.4464 - accuracy: 0.7839\n",
            "Epoch 234/300\n",
            "768/768 [==============================] - 0s 83us/step - loss: 0.4598 - accuracy: 0.7891\n",
            "Epoch 235/300\n",
            "768/768 [==============================] - 0s 76us/step - loss: 0.4542 - accuracy: 0.7917\n",
            "Epoch 236/300\n",
            "768/768 [==============================] - 0s 73us/step - loss: 0.4471 - accuracy: 0.7865\n",
            "Epoch 237/300\n",
            "768/768 [==============================] - 0s 76us/step - loss: 0.4567 - accuracy: 0.7812\n",
            "Epoch 238/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.4376 - accuracy: 0.7982\n",
            "Epoch 239/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4386 - accuracy: 0.7969\n",
            "Epoch 240/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4394 - accuracy: 0.7904\n",
            "Epoch 241/300\n",
            "768/768 [==============================] - 0s 91us/step - loss: 0.4417 - accuracy: 0.7982\n",
            "Epoch 242/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.4476 - accuracy: 0.7917\n",
            "Epoch 243/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4391 - accuracy: 0.8034\n",
            "Epoch 244/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4338 - accuracy: 0.8125\n",
            "Epoch 245/300\n",
            "768/768 [==============================] - 0s 76us/step - loss: 0.4468 - accuracy: 0.8099\n",
            "Epoch 246/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4526 - accuracy: 0.7943\n",
            "Epoch 247/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4455 - accuracy: 0.7982\n",
            "Epoch 248/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4431 - accuracy: 0.7865\n",
            "Epoch 249/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4373 - accuracy: 0.8203\n",
            "Epoch 250/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4446 - accuracy: 0.7995\n",
            "Epoch 251/300\n",
            "768/768 [==============================] - 0s 76us/step - loss: 0.4418 - accuracy: 0.8021\n",
            "Epoch 252/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4477 - accuracy: 0.7891\n",
            "Epoch 253/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4331 - accuracy: 0.7917\n",
            "Epoch 254/300\n",
            "768/768 [==============================] - 0s 89us/step - loss: 0.4290 - accuracy: 0.8099\n",
            "Epoch 255/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4483 - accuracy: 0.7878\n",
            "Epoch 256/300\n",
            "768/768 [==============================] - 0s 76us/step - loss: 0.4477 - accuracy: 0.7917\n",
            "Epoch 257/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4347 - accuracy: 0.8190\n",
            "Epoch 258/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4301 - accuracy: 0.8099\n",
            "Epoch 259/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4406 - accuracy: 0.7982\n",
            "Epoch 260/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4340 - accuracy: 0.8047\n",
            "Epoch 261/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4365 - accuracy: 0.8034\n",
            "Epoch 262/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4422 - accuracy: 0.7943\n",
            "Epoch 263/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4302 - accuracy: 0.8047\n",
            "Epoch 264/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4418 - accuracy: 0.7891\n",
            "Epoch 265/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4342 - accuracy: 0.8008\n",
            "Epoch 266/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4293 - accuracy: 0.8047\n",
            "Epoch 267/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4313 - accuracy: 0.8138\n",
            "Epoch 268/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4356 - accuracy: 0.8151\n",
            "Epoch 269/300\n",
            "768/768 [==============================] - 0s 75us/step - loss: 0.4318 - accuracy: 0.7969\n",
            "Epoch 270/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.4410 - accuracy: 0.8073\n",
            "Epoch 271/300\n",
            "768/768 [==============================] - 0s 76us/step - loss: 0.4316 - accuracy: 0.8112\n",
            "Epoch 272/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4426 - accuracy: 0.8021\n",
            "Epoch 273/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4450 - accuracy: 0.7865\n",
            "Epoch 274/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4389 - accuracy: 0.8073\n",
            "Epoch 275/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4271 - accuracy: 0.8112\n",
            "Epoch 276/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4314 - accuracy: 0.8021\n",
            "Epoch 277/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4332 - accuracy: 0.8034\n",
            "Epoch 278/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4467 - accuracy: 0.8008\n",
            "Epoch 279/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.4371 - accuracy: 0.7943\n",
            "Epoch 280/300\n",
            "768/768 [==============================] - 0s 75us/step - loss: 0.4387 - accuracy: 0.7930\n",
            "Epoch 281/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4379 - accuracy: 0.7982\n",
            "Epoch 282/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4310 - accuracy: 0.7956\n",
            "Epoch 283/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4276 - accuracy: 0.8021\n",
            "Epoch 284/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4261 - accuracy: 0.8125\n",
            "Epoch 285/300\n",
            "768/768 [==============================] - 0s 77us/step - loss: 0.4370 - accuracy: 0.8008\n",
            "Epoch 286/300\n",
            "768/768 [==============================] - 0s 87us/step - loss: 0.4317 - accuracy: 0.8099\n",
            "Epoch 287/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4247 - accuracy: 0.8138\n",
            "Epoch 288/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.4262 - accuracy: 0.8021\n",
            "Epoch 289/300\n",
            "768/768 [==============================] - 0s 82us/step - loss: 0.4255 - accuracy: 0.8086\n",
            "Epoch 290/300\n",
            "768/768 [==============================] - 0s 78us/step - loss: 0.4342 - accuracy: 0.8047\n",
            "Epoch 291/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4339 - accuracy: 0.8008\n",
            "Epoch 292/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4295 - accuracy: 0.7995\n",
            "Epoch 293/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.4293 - accuracy: 0.8008\n",
            "Epoch 294/300\n",
            "768/768 [==============================] - 0s 81us/step - loss: 0.4280 - accuracy: 0.8099\n",
            "Epoch 295/300\n",
            "768/768 [==============================] - 0s 85us/step - loss: 0.4370 - accuracy: 0.8099\n",
            "Epoch 296/300\n",
            "768/768 [==============================] - 0s 84us/step - loss: 0.4389 - accuracy: 0.8008\n",
            "Epoch 297/300\n",
            "768/768 [==============================] - 0s 86us/step - loss: 0.4308 - accuracy: 0.8047\n",
            "Epoch 298/300\n",
            "768/768 [==============================] - 0s 83us/step - loss: 0.4288 - accuracy: 0.8008\n",
            "Epoch 299/300\n",
            "768/768 [==============================] - 0s 80us/step - loss: 0.4280 - accuracy: 0.8086\n",
            "Epoch 300/300\n",
            "768/768 [==============================] - 0s 79us/step - loss: 0.4250 - accuracy: 0.8086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnTEwt-0posr",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaSqfwJKogX5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "666ac6ec-6ea1-423a-dae1-3e0bc625fb48"
      },
      "source": [
        "# evaluate the model \n",
        "scores = model.evaluate(X, Y) \n",
        "model.metrics_names[1], scores[1]*100"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "768/768 [==============================] - 0s 40us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('accuracy', 78.90625)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0sKVeB6qbv4",
        "colab_type": "text"
      },
      "source": [
        "#Plotting it all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDD7cSlAp9jz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b72da212-9f02-4e04-c537-a45aabf185e2"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C05uiHXHqfOq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "534bad68-c1c9-42f7-f84c-12902f177367"
      },
      "source": [
        "epochs_hist.history.keys()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvG9trx9qooY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "85f69b0b-8d6e-4cf4-e624-c3b0ccf5cdb4"
      },
      "source": [
        "plt.plot(epochs_hist.history['loss'])\n",
        "plt.title('Model Loss Progress During Training')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training and Validation Loss')\n",
        "plt.legend(['Training Loss']);"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}