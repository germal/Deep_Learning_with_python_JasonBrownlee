{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9.3 Grid Search Deep Learning Model Parameters - Pima Dataset.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNpTMXmyjFmbBru3/gW4VaP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelounb/Deep_Learning_with_python_JasonBrownlee/blob/master/9_3_Grid_Search_Deep_Learning_Model_Parameters_Pima_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvKOhxrOhpmC",
        "colab_type": "text"
      },
      "source": [
        "# 9.3 Grid Search Deep Learning Model Parameters\n",
        " The previous example showed how easy it is to wrap your deep learning model from Keras and use it in functions from the scikit-learn library. In this example we go a step further. We already know we can provide arguments to the fit() function. \n",
        " \n",
        "The function that we specify to the build_fn argument when creating the KerasClassifier wrapper can also take arguments. We can use these arguments to further customize the construction of the model. In this example we use a grid search to evaluate different conﬁgurations for our neural network model and report on the combination that provides the best estimated performance. \n",
        "\n",
        "The create model() function is deﬁned to take two arguments optimizer and init, both of which must have default values. This will allow us to evaluate the effect of using di↵erent optimization algorithms and weight initialization schemes for our network. After creating our model, we deﬁne arrays of values for the parameter we wish to search, speciﬁcally:\n",
        "\n",
        "1. Optimizers for searching different weight values.\n",
        "2. Initializers for preparing the network weights using di↵erent schemes.\n",
        "3. Number of epochs for training the model for di↵erent number of exposures to the training dataset.\n",
        "4. Batches for varying the number of samples before weight updates\n",
        "\n",
        "The options are speciﬁed into a dictionary and passed to the conﬁguration of the GridSearchCV scikit-learn class. This class will evaluate a version of our neural network model for each combination of parameters (2⇥3⇥3⇥3) for the combinations of optimizers, initializations, epochs and batches). \n",
        "\n",
        "Each combination is then evaluated using the default of 3-fold stratiﬁed cross validation. That is a lot of models and a lot of computation. This is not a scheme that you want to use lightly because of the time it will take to compute. It may be useful for you to design small experiments with a smaller subset of your data that will complete in a reasonable time. \n",
        "\n",
        "This experiment is reasonable in this case because of the small network and the small dataset (less than 1,000 instances and 9 attributes). Finally, the performance and combination of conﬁgurations for the best model are displayed, followed by the performance of all combinations of parameters.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CPE29t-Bfaf",
        "colab_type": "code",
        "outputId": "f6f46209-44ab-43f7-c4b9-43188510b0dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "import numpy as np\n",
        "# fix random seed for reproducibility \n",
        "seed = 7 \n",
        "np.random.seed(seed)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NphmfwqhkpTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load pima indians dataset \n",
        "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\") \n",
        "# split into input (X) and output (Y) variables \n",
        "X = dataset[:,0:8] \n",
        "Y = dataset[:,8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H39mtChk8Dv",
        "colab_type": "code",
        "outputId": "2e9ebd00-777a-4141-984e-f48bd0ba910c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc6Nxpalk_S7",
        "colab_type": "code",
        "outputId": "0764bcdd-2079-407d-f7fe-aee04ba6041f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUmTb6x6SK4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94cvG06UQZDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create model, required for KerasClassifier \n",
        "def create_model(optimizer='rmsprop' , kernel_initializer= 'glorot_uniform' ):\n",
        "  # create model \n",
        "  model = Sequential() \n",
        "  model.add(Dense(12, input_dim=8, kernel_initializer=kernel_initializer , activation= 'relu' )) \n",
        "  model.add(Dense(8, kernel_initializer= 'uniform' , activation= 'relu' )) \n",
        "  model.add(Dense(1, kernel_initializer= 'uniform' , activation= 'sigmoid' ))\n",
        "  # Compile model \n",
        "  model.compile(loss= 'binary_crossentropy' , optimizer=optimizer , metrics=[ 'accuracy' ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9raqyW4R8rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model \n",
        "model = KerasClassifier(build_fn=create_model, verbose=0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFnm5CDtSn8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grid search epochs, batch size and optimizer \n",
        "optimizers = [ 'rmsprop' , 'adam' ] \n",
        "kernel_initializer = [ 'glorot_uniform' , 'normal' , 'uniform' ] \n",
        "epochs = np.array([5, 10, 15]) \n",
        "batches = np.array([5, 10, 20]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5SRpf4RYMlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = dict(optimizer=optimizers,  kernel_initializer=kernel_initializer)  # batch_size=batches, epochs=epochs, \n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid) \n",
        "grid_result = grid.fit(X, Y) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr_VUrGdZEkw",
        "colab_type": "text"
      },
      "source": [
        "This might take about 5 minutes to complete on your workstation executed on the CPU. running the example shows the results below. We can see that the grid search discovered that using a uniform initialization scheme, rmsprop optimizer, 150 epochs and a batch size of 5 achieved the best cross validation score of approximately 75% on this problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70FsQFkSYwzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ae52c1d0-9331-40ac-9636-a6f1736f93a5"
      },
      "source": [
        "# summarize results \n",
        "print(grid_result.best_score_, grid_result.best_params_) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.652457344532013 {'kernel_initializer': 'uniform', 'optimizer': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXqTpMXnY90B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a259852e-9941-437d-c978-b677c6da144e"
      },
      "source": [
        "\"\"\"for params, mean_score, scores in grid_result.score: \n",
        "  print(scores.mean(), scores.std(), params)\"\"\""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for params, mean_score, scores in grid_result.score: \\n  print(scores.mean(), scores.std(), params)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}