{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10.1 Iris Flowers Classiﬁcation Dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCtQ0CjjYUo64EMKgfOSEX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelounb/Deep_Learning_with_python_JasonBrownlee/blob/master/10_1_Iris_Flowers_Classi%EF%AC%81cation_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxYzSX017CIq",
        "colab_type": "text"
      },
      "source": [
        "# Project: Multiclass Classiﬁcation Of Flower Species\n",
        "\n",
        "In this tutorial we will use the standard machine learning problem called the iris ﬂowers dataset. This dataset is well studied and is a good problem for practicing on neural networks because all of the 4 input variables are numeric and have the same scale in centimeters. Each instance describes the properties of an observed ﬂower measurements and the output variable is speciﬁc iris species. The attributes for this dataset can be summarized as follows:\n",
        "1. Sepal length in centimeters.\n",
        "2. Sepal width in centimeters.\n",
        "3. Petal length in centimeters.\n",
        "4. Petal width in centimeters.\n",
        "5. Class (Iris-setosa, Iris-versicolour, Iris-virginica).\n",
        "\n",
        "\n",
        "This is a multiclass classiﬁcation problem, meaning that there are more than two classes to be predicted, in fact there are three ﬂower species. This is an important type of problem on which to practice with neural networks because the three class values require specialized handling. Below is a sample of the ﬁrst ﬁve of the 150 instances:\n",
        "\n",
        "5.1,3.5,1.4,0.2,Iris-setosa \n",
        "\n",
        "4.9,3.0,1.4,0.2,Iris-setosa \n",
        "\n",
        "4.7,3.2,1.3,0.2,Iris-setosa \n",
        "\n",
        "4.6,3.1,1.5,0.2,Iris-setosa \n",
        "\n",
        "5.0,3.6,1.4,0.2,Iris-setosa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph1nCojI7-l2",
        "colab_type": "text"
      },
      "source": [
        "The iris ﬂower dataset is a well studied problem and a such we can expect to achieve a model accuracy in the range of 95% to 97%. This provides a good target to aim for when developing our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX5ihSgWzwSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier \n",
        "from keras.utils import np_utils \n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkfQ9Fq1UZ4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load dataset \n",
        "dataframe = pd.read_csv(\"/content/iris.data\", header=None) \n",
        "dataset = dataframe.values \n",
        "X = dataset[:,0:4].astype(float) \n",
        "Y = dataset[:,4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5lXkWcRUJY4",
        "colab_type": "text"
      },
      "source": [
        "Understanding the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33jAdWveUGN9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19f65e6a-a10a-4bc1-c2b6-2680531e0327"
      },
      "source": [
        "print(X.shape, Y.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4) (150,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qLeRfGxUlp9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "89160b73-b516-4b02-9b49-5b3b4aadcce4"
      },
      "source": [
        "dataset[:10]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2, 'Iris-setosa'],\n",
              "       [4.9, 3.0, 1.4, 0.2, 'Iris-setosa'],\n",
              "       [4.7, 3.2, 1.3, 0.2, 'Iris-setosa'],\n",
              "       [4.6, 3.1, 1.5, 0.2, 'Iris-setosa'],\n",
              "       [5.0, 3.6, 1.4, 0.2, 'Iris-setosa'],\n",
              "       [5.4, 3.9, 1.7, 0.4, 'Iris-setosa'],\n",
              "       [4.6, 3.4, 1.4, 0.3, 'Iris-setosa'],\n",
              "       [5.0, 3.4, 1.5, 0.2, 'Iris-setosa'],\n",
              "       [4.4, 2.9, 1.4, 0.2, 'Iris-setosa'],\n",
              "       [4.9, 3.1, 1.5, 0.1, 'Iris-setosa']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TVyB5Z-VjSJ",
        "colab_type": "text"
      },
      "source": [
        "# Initialize Random Number Generator\n",
        "Next we need to initialize the random number generator to a constant value. This is important to ensure that the results we achieve from this model can be achieved again precisely. It ensures that the stochastic process of training a neural network model can be reproduced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-Eo_5wTWQ9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix random seed for reproducibility \n",
        "seed = 7 \n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AdkVVTAWgwk",
        "colab_type": "text"
      },
      "source": [
        "# Encode The Output Variable\n",
        "The output variable contains three di↵erent string values. When modeling multiclass classiﬁcation problems using neural networks, it is good practice to reshape the output attribute from a vector that contains values for each class value to be a matrix with a boolean for each class value and whether or not a given instance has that class value or not. This is called one hot encoding or creating dummy variables from a categorical variable. For example, in this problem the three class values are Iris-setosa, Iris-versicolor and Iris-virginica. If we had the three observations:\n",
        "1. Iris-setosa \n",
        "2. Iris-versicolor \n",
        "3. Iris-virginic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFoPSQQNWjF_",
        "colab_type": "text"
      },
      "source": [
        "We can turn this into a one-hot encoded binary matrix for each data instance that would look as follows:\n",
        "\n",
        "Iris-setosa, Iris-versicolor, Iris-virginica \n",
        "\n",
        "1, 0, 0\n",
        "\n",
        "0, 1, 0\n",
        " \n",
        "0, 0, 1\n",
        "\n",
        "We can do this by ﬁrst encoding the strings consistently to integers using the scikit-learn class LabelEncoder. Then convert the vector of integers to a one hot encoding using the Keras function to categorical()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyiO7ZecW9W1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode class values as integers \n",
        "encoder = LabelEncoder() \n",
        "encoder.fit(Y) \n",
        "encoded_Y = encoder.transform(Y) \n",
        "# convert integers to dummy variables (i.e. one hot encoded) \n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZm8v8QsddP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "d55e0cf8-d3d9-4fb7-94a4-9f0a0cf52117"
      },
      "source": [
        "encoded_Y"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM7gdJQKdhKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "d255cdc6-7fe6-44a8-ad48-e4772c64cff7"
      },
      "source": [
        "dummy_y[45:55]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtnpnN7Aek63",
        "colab_type": "text"
      },
      "source": [
        "# Deﬁne The Neural Network Model\n",
        "a simple fully connected network with one hidden layer that contains 4 neurons, the same number of inputs (it could be any number of neurons). \n",
        "\n",
        "The hidden layer uses a rectiﬁer activation function which is a good practice. Because we used a one-hot encoding for our iris dataset, the output layer must create 3 output values, one for each class. \n",
        "\n",
        "The output value with the largest value will be taken as the class predicted by the model. The network topology of this simple one-layer neural network can be summarized as:\n",
        "\n",
        "4 inputs -> [4 hidden nodes] -> 3 outputs\n",
        "\n",
        "Note that we use a sigmoid activation function in the output layer. This is to ensure the output values are in the range of 0 and 1 and may be used as predicted probabilities. Finally, the network uses the ecient ADAM gradient descent optimization algorithm with a logarithmic loss function, which is called categorical crossentropy in Keras.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kWP4FfwfH2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define baseline model \n",
        "def baseline_model(): \n",
        "  # create model \n",
        "  model = Sequential() \n",
        "  model.add(Dense(4, input_dim=4, init= 'normal' , activation= 'relu' )) \n",
        "  model.add(Dense(3, init=  'normal' , activation= 'sigmoid' )) \n",
        "  # Compile model \n",
        "  model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ]) \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA63S413femt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}